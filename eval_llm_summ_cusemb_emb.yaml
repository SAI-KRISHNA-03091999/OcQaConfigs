dataset: SSS

generate_ground_truth: true
questions_generator:
    prompt: "default"
    num_questions_per_chunk: 1
    max_chunks: 10     # Maximum number of chunks to be used for question generation
    llm: openai
    llmkey: "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"
    llmurl: ""
    max_tokens: 2048

#ground_truth: "/home/data/GIconfigs/ground_truth316.csv"


rag_configuration: "/home/sai-neralla/OcQaConfigs/rag_llm_embedding.yaml"

vectorstore: weaviate_vectorstore
weaviate_vectorstore:
    url: ""
    auth_key: ""
    provider: dkubex
    properties: 
    - paperchunks
    - dkubexfm

evaluator:
  - semantic_similarity_evaluator       # Vector Similarity
  - correctness_evaluator               # LLM Similarity
  - answer_relevancy_evaluator
  - retrieval_evaluator

semantic_similarity_evaluator:
    prompt: "default"
    llm: dkubex #openai#dkubex
    llm_url: ""
    llmkey: ""
    max_tokens: 2048
    metrics:
    - similarity_score

correctness_evaluator:
    prompt: default
    llm: dkubex  #openai # "dkubex" for dkubex deployments
    llm_url: ""
    llmkey: ""
    max_tokens: 2048

answer_relevancy_evaluator:
    prompt: "default"
    llm: dkubex #use "dkubex" for dkubex deployments
    llm_url: ""
    llmkey: ""
    max_tokens: 2048

retrieval_evaluator:
    weaviate_vectorstore:
        kind: weaviate
        vectorstore_provider: dkubex
        textkey: paperchunks
        embedding_provider: sky
        embedding_url: 
        embedding_key: 
        similarity_top_k: 3
    metrics:
    - mrr
    - hit_rate

tracking:
    experiment: Evaluate-tests-Krishna
    
    
##This is the command to exicute eval    
##d3x dataset evaluate -c /home/ocdlgit/shashank/eval_config.yaml 
